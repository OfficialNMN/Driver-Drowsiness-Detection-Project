{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"id":"hk49VKtuDBNW"}},{"cell_type":"code","source":"import cv2, os\nimport random,shutil\nimport numpy as np\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.image import imread\nimport tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers, Model\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\n\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n","metadata":{"id":"9fXY_-Tqv-kU","execution":{"iopub.status.busy":"2022-01-15T19:30:38.191279Z","iopub.execute_input":"2022-01-15T19:30:38.191604Z","iopub.status.idle":"2022-01-15T19:30:38.201344Z","shell.execute_reply.started":"2022-01-15T19:30:38.191575Z","shell.execute_reply":"2022-01-15T19:30:38.200387Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/drowsiness-detection","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:52:19.539199Z","iopub.execute_input":"2022-01-15T18:52:19.539515Z","iopub.status.idle":"2022-01-15T18:52:20.308070Z","shell.execute_reply.started":"2022-01-15T18:52:19.539487Z","shell.execute_reply":"2022-01-15T18:52:20.307012Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/drowsiness-detection'","metadata":{"id":"KMS6yVPUAhBL","execution":{"iopub.status.busy":"2022-01-15T19:30:39.883022Z","iopub.execute_input":"2022-01-15T19:30:39.883336Z","iopub.status.idle":"2022-01-15T19:30:39.887152Z","shell.execute_reply.started":"2022-01-15T19:30:39.883306Z","shell.execute_reply":"2022-01-15T19:30:39.886266Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Image Data Generator and Data Augmentation","metadata":{"id":"tyWVxuUnzP-K"}},{"cell_type":"code","source":"def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),\n              class_mode='categorical' ):\n\n    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',\n                                   class_mode=class_mode,target_size=target_size)\n\nbatch= 32\ntarget=(24,24)\ntrain_batch = generator(data_dir,shuffle=True, batch_size=batch,target_size=target)\nvalid_batch = generator(data_dir,shuffle=True, batch_size=batch,target_size=target)\nsize_per_epoch= len(train_batch.classes)//batch\nvalidation_size = len(valid_batch.classes)//batch\nprint(size_per_epoch,validation_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:30:42.709975Z","iopub.execute_input":"2022-01-15T19:30:42.710310Z","iopub.status.idle":"2022-01-15T19:30:51.163819Z","shell.execute_reply.started":"2022-01-15T19:30:42.710275Z","shell.execute_reply":"2022-01-15T19:30:51.162885Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Using Basic CNN Architecture","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n    MaxPooling2D(pool_size=(1,1)),\n    Conv2D(32,(3,3),activation='relu'),\n    MaxPooling2D(pool_size=(1,1)),\n    #32 convolution filters used each of size 3x3 again\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(1,1)),\n    #64 convolution filters used each of size 3x3 choose the best features via pooling\n    #randomly turn neurons on and off to improve convergence\n    Dropout(0.25),\n    #flatten since too many dimensions, we only want a classification output\n    Flatten(),\n    #fully connected to get all relevant data\n    Dense(128, activation='relu'),\n    #one more dropout for convergence' sake :) \n    Dropout(0.5),\n    #output a softmax to squash the matrix into output probabilities\n    Dense(2, activation='softmax')\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:30:54.185589Z","iopub.execute_input":"2022-01-15T19:30:54.185927Z","iopub.status.idle":"2022-01-15T19:30:54.295734Z","shell.execute_reply.started":"2022-01-15T19:30:54.185896Z","shell.execute_reply":"2022-01-15T19:30:54.295030Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit_generator(train_batch, validation_data=valid_batch,epochs=2,steps_per_epoch=Size_per_epoch ,validation_steps=validation_size)\nmodel.save('CNN_Drowsiness.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:32:02.972928Z","iopub.execute_input":"2022-01-15T19:32:02.973326Z","iopub.status.idle":"2022-01-15T19:38:49.442379Z","shell.execute_reply.started":"2022-01-15T19:32:02.973288Z","shell.execute_reply":"2022-01-15T19:38:49.441228Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Using ResNet-50 Transfer Learning Technique","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(validation_split=0.3,\n                                   preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory( data_dir,\n                                                     target_size=(224,224),\n                                                     batch_size=100,\n                                                     shuffle=True,\n                                                     class_mode='binary',\n                                                     subset='training')\n\nvalidation_datagen = ImageDataGenerator(validation_split=0.3,\n                                        preprocessing_function=preprocess_input)\n\nvalidation_generator =  validation_datagen.flow_from_directory( data_dir,\n                                                                target_size=(224,224),\n                                                                batch_size=100,\n                                                                class_mode='binary',\n                                                                subset='validation')  ","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:51:17.167019Z","iopub.execute_input":"2022-01-15T19:51:17.167342Z","iopub.status.idle":"2022-01-15T19:51:25.077834Z","shell.execute_reply.started":"2022-01-15T19:51:17.167311Z","shell.execute_reply":"2022-01-15T19:51:25.076890Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_res50 = Sequential()\n\nmodel_res50.add(ResNet50(\n    include_top=False,\n    pooling='avg',\n    weights='imagenet'\n    ))\n\nmodel_res50.add(Dense(2, activation='softmax'))\nmodel_res50.layers[0].trainable = False \nmodel_res50.summary()\n\nsteps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:39:16.321653Z","iopub.execute_input":"2022-01-15T19:39:16.322018Z","iopub.status.idle":"2022-01-15T19:39:20.491106Z","shell.execute_reply.started":"2022-01-15T19:39:16.321986Z","shell.execute_reply":"2022-01-15T19:39:20.490350Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model_res50.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\nhistory = model_res50.fit(\n    train_generator,\n    steps_per_epoch=10,\n    validation_steps=10,\n    epochs=3,\n    validation_data=validation_generator,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:40:18.437473Z","iopub.execute_input":"2022-01-15T19:40:18.437847Z","iopub.status.idle":"2022-01-15T19:51:09.933715Z","shell.execute_reply.started":"2022-01-15T19:40:18.437811Z","shell.execute_reply":"2022-01-15T19:51:09.932867Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model_res50.save('ResNet50_Drowsiness.h5')","metadata":{"id":"WmXbe85U9Nx-","execution":{"iopub.status.busy":"2022-01-15T19:52:12.155248Z","iopub.execute_input":"2022-01-15T19:52:12.155628Z","iopub.status.idle":"2022-01-15T19:52:12.446319Z","shell.execute_reply.started":"2022-01-15T19:52:12.155597Z","shell.execute_reply":"2022-01-15T19:52:12.445497Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n# Retrieve a list of list results on training and test data sets for each training epoch\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n\n# Plot training and validation loss per epoch\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"id":"NGM4HaAi9N1X","execution":{"iopub.status.busy":"2022-01-15T19:52:20.125431Z","iopub.execute_input":"2022-01-15T19:52:20.125856Z","iopub.status.idle":"2022-01-15T19:52:20.491412Z","shell.execute_reply.started":"2022-01-15T19:52:20.125816Z","shell.execute_reply":"2022-01-15T19:52:20.490697Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}