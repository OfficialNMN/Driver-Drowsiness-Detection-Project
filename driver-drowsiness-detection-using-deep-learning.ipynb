{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"id":"hk49VKtuDBNW"}},{"cell_type":"code","source":"import cv2, os\nimport random,shutil\nimport numpy as np\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.image import imread\nimport tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers, Model\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\n\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization","metadata":{"id":"9fXY_-Tqv-kU","execution":{"iopub.status.busy":"2022-01-16T08:37:59.441326Z","iopub.execute_input":"2022-01-16T08:37:59.441685Z","iopub.status.idle":"2022-01-16T08:37:59.453152Z","shell.execute_reply.started":"2022-01-16T08:37:59.441654Z","shell.execute_reply":"2022-01-16T08:37:59.452250Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/drowsiness-detection","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:38:00.447771Z","iopub.execute_input":"2022-01-16T08:38:00.448173Z","iopub.status.idle":"2022-01-16T08:38:01.185377Z","shell.execute_reply.started":"2022-01-16T08:38:00.448140Z","shell.execute_reply":"2022-01-16T08:38:01.184452Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/drowsiness-detection'","metadata":{"id":"KMS6yVPUAhBL","execution":{"iopub.status.busy":"2022-01-16T08:38:01.961262Z","iopub.execute_input":"2022-01-16T08:38:01.961617Z","iopub.status.idle":"2022-01-16T08:38:01.968384Z","shell.execute_reply.started":"2022-01-16T08:38:01.961583Z","shell.execute_reply":"2022-01-16T08:38:01.967336Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Image Data Generator and Data Augmentation","metadata":{"id":"tyWVxuUnzP-K"}},{"cell_type":"code","source":"def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),\n              class_mode='categorical' ):\n\n    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',\n                                   class_mode=class_mode,target_size=target_size)\n\nbatch= 32\ntarget=(24,24)\ntrain_batch = generator(data_dir,shuffle=True, batch_size=batch,target_size=target)\nvalid_batch = generator(data_dir,shuffle=True, batch_size=batch,target_size=target)\nsize_per_epoch= len(train_batch.classes)//batch\nvalidation_size = len(valid_batch.classes)//batch\nprint(size_per_epoch,validation_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:38:29.646969Z","iopub.execute_input":"2022-01-16T08:38:29.647300Z","iopub.status.idle":"2022-01-16T08:38:39.193623Z","shell.execute_reply.started":"2022-01-16T08:38:29.647271Z","shell.execute_reply":"2022-01-16T08:38:39.192640Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Using Basic CNN Architecture","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n    MaxPooling2D(pool_size=(1,1)),\n    Conv2D(32,(3,3),activation='relu'),\n    MaxPooling2D(pool_size=(1,1)),\n    #32 convolution filters used each of size 3x3 again\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(1,1)),\n    #64 convolution filters used each of size 3x3 choose the best features via pooling\n    #randomly turn neurons on and off to improve convergence\n    Dropout(0.25),\n    #flatten since too many dimensions, we only want a classification output\n    Flatten(),\n    #fully connected to get all relevant data\n    Dense(128, activation='relu'),\n    #one more dropout for convergence' sake :) \n    Dropout(0.5),\n    #output a softmax to squash the matrix into output probabilities\n    Dense(2, activation='softmax')\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:38:42.539584Z","iopub.execute_input":"2022-01-16T08:38:42.539938Z","iopub.status.idle":"2022-01-16T08:38:42.627595Z","shell.execute_reply.started":"2022-01-16T08:38:42.539897Z","shell.execute_reply":"2022-01-16T08:38:42.626873Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit_generator(train_batch, validation_data=valid_batch,epochs=2,steps_per_epoch=size_per_epoch ,validation_steps=validation_size)\nmodel.save('CNN_Drowsiness.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:38:43.770638Z","iopub.execute_input":"2022-01-16T08:38:43.771083Z","iopub.status.idle":"2022-01-16T08:42:53.271209Z","shell.execute_reply.started":"2022-01-16T08:38:43.771042Z","shell.execute_reply":"2022-01-16T08:42:53.270216Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Using ResNet-50 Transfer Learning Technique","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(validation_split=0.3,\n                                   preprocessing_function=preprocess_input) \n\ntrain_generator = train_datagen.flow_from_directory( data_dir,\n                                                     target_size=(224,224),\n                                                     batch_size=100,\n                                                     shuffle=True,\n                                                     class_mode='binary',\n                                                     subset='training')\n\nvalidation_datagen = ImageDataGenerator(validation_split=0.3,\n                                        preprocessing_function=preprocess_input)\n\nvalidation_generator =  validation_datagen.flow_from_directory( data_dir,\n                                                                target_size=(224,224),\n                                                                batch_size=100,\n                                                                class_mode='binary',\n                                                                subset='validation')  ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:43:23.356742Z","iopub.execute_input":"2022-01-16T08:43:23.357103Z","iopub.status.idle":"2022-01-16T08:43:28.907178Z","shell.execute_reply.started":"2022-01-16T08:43:23.357071Z","shell.execute_reply":"2022-01-16T08:43:28.906207Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_res50 = Sequential()\n\nmodel_res50.add(ResNet50(\n    include_top=False,\n    pooling='avg',\n    weights='imagenet'\n    ))\n\nmodel_res50.add(Dense(1, activation='sigmoid'))\nmodel_res50.layers[0].trainable = False \nmodel_res50.summary()\n\nsteps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:43:28.908959Z","iopub.execute_input":"2022-01-16T08:43:28.909308Z","iopub.status.idle":"2022-01-16T08:43:30.737243Z","shell.execute_reply.started":"2022-01-16T08:43:28.909270Z","shell.execute_reply":"2022-01-16T08:43:30.735823Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_res50.compile(optimizer='adam', \n              loss='binary_crossentropy', \n              metrics=['accuracy'])\n\nhistory = model_res50.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch_training,\n    validation_steps=steps_per_epoch_validation,\n    epochs=3,\n    validation_data=validation_generator,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T08:43:30.738526Z","iopub.execute_input":"2022-01-16T08:43:30.738959Z","iopub.status.idle":"2022-01-16T08:51:24.324918Z","shell.execute_reply.started":"2022-01-16T08:43:30.738911Z","shell.execute_reply":"2022-01-16T08:51:24.324148Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model_res50.save('ResNet50_Drowsiness.h5')","metadata":{"id":"WmXbe85U9Nx-","execution":{"iopub.status.busy":"2022-01-16T08:51:33.318405Z","iopub.execute_input":"2022-01-16T08:51:33.318761Z","iopub.status.idle":"2022-01-16T08:51:33.804152Z","shell.execute_reply.started":"2022-01-16T08:51:33.318719Z","shell.execute_reply":"2022-01-16T08:51:33.801962Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n# Retrieve a list of list results on training and test data sets for each training epoch\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n\n# Plot training and validation loss per epoch\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"id":"NGM4HaAi9N1X","execution":{"iopub.status.busy":"2022-01-16T08:51:38.976011Z","iopub.execute_input":"2022-01-16T08:51:38.976373Z","iopub.status.idle":"2022-01-16T08:51:39.228734Z","shell.execute_reply.started":"2022-01-16T08:51:38.976344Z","shell.execute_reply":"2022-01-16T08:51:39.227868Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}